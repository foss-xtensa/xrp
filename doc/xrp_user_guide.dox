# Copyright (c) 2018 Cadence Design Systems, Inc.
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be included
# in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

/*!

\page introduction Introduction
\idxentry{Introduction}

Xtensa Remote Processing (XRP) is a communication interface for Linux-based
systems containing Xtensa processors. It allows Linux userspace tasks to send
messages to the firmware running on Xtensa processors. Its implementations
support master-slave communication model with a single host node sending messages
and one or more DSP nodes executing actions requested in received messages and
returning the results. Message structure details are not defined by the XRP,
but it is assumed that the message is a small structure that describes requested
action accompanied by a vector of buffers with data or storage for that action.

\section introduction_goals Goals
\idxentry{Introduction!Goals}

XRP has been designed and implemented with the following major goals in mind:
- Isolate users from the details of memory subsystem and support passing buffers
  with all types of memory between the host and DSPs transparently
- Allow for effective (without copying) sharing of buffers between the userspace
  process and the DSP firmware
- Provide single set of API calls that allows running user code without
  modifications natively and in various simulation/debug modes
- Allow for porting to new hardware without modification of the existing code

\section introduction_terminology Terminology
\idxentry{Introduction!Terminology}

XRP API uses the following terms:

- Buffer: a descriptor for a contiguous piece of memory. A buffer must be
          mapped before its memory is accessible. A buffer may be allocated in
          the device specific memory or in the generic system memory. A buffer
          in the device specific memory is the most effective way to pass
          bulk data to/from the Xtensa DSP, it is physically contiguous and
          data transfer does not require copying. Buffer in the generic system
          memory may be physically noncontiguous and tranferring data may
          require copying to/from the intermediate bounce buffer.

- Buffer group: a vector of buffers and associated allowed access flags.
                Buffers are numbered sequentially from 0 to N - 1. A buffer
                may be added to the end of a group. A buffer descriptor may be
                acquired from the buffer group by index. A buffer may be added
                to a buffer group with the access flags allowing reading,
                writing or both. These access flags limit the ways in which
                the buffer descriptor acquired from the buffer group may be
                mapped.

- Device: single Xtensa DSP core. Devices are numbered sequentially from 0
          to N - 1. There's an API call that opens device by its number.

- Message: a unit of communication between the XRP API users. A message may be
           sent by the master to a queue synchronously or asynchronously. It
           is processed synchronously by the Xtensa DSP and the reply is
           delivered back to master. If a message was sent synchronously the
           sender is unblocked at that point. If a message was sent
           asynchronously the sender gets an event object that can be used to
           wait for the message processing completion.
           A message takes a small read-only region of memory with a message
           description data, a small write-only region of memory where the
           result description data is written and a buffer group with buffers
           for the bulk data being processed.


- Namespace: an independent command handler on the DSP side identified by an
             UUID. Multiple namespaces may be active on the DSP side
             simultaneously. Namespace may be registered and deregistered
             dynamically.

- Queue: a communication stream between an application and a namespace on a
         device. Commands queued into one queue are processed in order and
         there's no ordering between commands in different queues.

\latexonly \newpage \endlatexonly
\section introduction_requirements Requirements
\idxentry{Introduction!Requirements}

The DSP side XRP code does not have any specific hardware requirements, it should
work on a very broad range of Xtensa cores. It is tested with Xtensa
software versions RF.5 and later.

The Linux kernel driver is tested with a number of Linux kernel versions from
3.18 to 5.4 and is known to work on Xtensa, 32- and 64-bit ARM and x86 Linux.

The driver makes the following assumptions:
- The DSP has the same endianness as the host.
- The DSP memory where firmware must be loaded (possibly including DRAM and IRAM)
  is writable from the Linux host. The host may access that memory at physical
  addresses different from their physical addresses used by the DSP (i.e.,
  multiple DSPs may have identical configurations, and thus IRAM and DRAM at
  the same addresses, but the host needs to see each IRAM and DRAM at physical
  addresses that do not overlap to load firmware to each DSP).
- The driver provides functions to manage contiguous memory allocation for the
  DSP. These functions manage the physical memory pool configured for the DSP.
  The DSP must have access to all of this physical memory, but not necessarily
  at the same physical address as the host.
- The generic XRP driver is sufficient for the shared-memory based operation with
  the host and DSPs working in polling mode. If there are hardware-specific steps
  needed to enable DSPs, or DSPs or host need to work in the IRQ mode, then an
  additional hardware-specific XRP driver is needed for that system.

In the package an example driver is provided, xrp_hw_simple, which may be used as a
reference/template. It makes the following assumptions:
- Each DSP core has reset and runstall memory-mapped registers,
  the DSP does not need any additional setup to run (such as no clock setup, no power
  management, default reset vector).
- There may exist a memory-mapped register for sending an IRQ to the DSP core; if it
  exists, then in addition to the always available polling mode the DSP firmware
  may run in the IRQ mode.
- There may exist a memory-mapped register for sending the IRQ from the DSP to the host;
  if it exists, then in addition to the always available polling mode the Linux
  driver may run in the IRQ mode.


\section introduction_licensing Licensing
\idxentry{Introduction!Licensing}

The host and DSP XRP library code and examples are licensed under an MIT-style open
source license. The Linux kernel driver code is dual-licensed under an MIT-style open
source license and under the GPLv2+ license.


\page implementations XRP Implementations
\idxentry{Implementations}

There are three implementations of the XRP interface for the host side: hosted,
standalone, and single image.
The hosted implementation requires additional support from the host OS, which is
provided through the OS kernel driver. The standalone implementation communicates with the
DSP directly and is self-sufficient. The single image implementation runs the host and
DSP code in a single process context, requests are either served synchronously
or asynchronously in the XRP queue thread context.
The DSP XRP implementation can be configured to work with either hosted or
standalone host XRP. The Single image implementation does not use the DSP XRP code and
is not Xtensa specific.

\section implementations_hosted Hosted Implementation
\idxentry{Implementations!Hosted}

A hosted implementation runs on a system where CPU cores running host OS code
and Xtensa DSP cores are connected to shared memory. It may be a hardware or
a simulated system. It consists of the following three parts: a hosted host
implementation of the XRP interface, an OS kernel driver, and a DSP implementation
of the XRP interface.

\latexonly
\begin{figure}[h]
\centering
\begin{maxsizebox}{7cm}{7cm}
\begin{minipage}{\textwidth}
\endlatexonly
<pre>
  ,--------.
  | System |
  |        `------------------------------------------------------------.
  |  ,-----------.                          ,-------.-------.           |
  |  | Host CPUS |                          | DSP 0 | DSP 1 | ...       |
  |  |           `----------------------.   |       `-------------.     |
  |  | ,--------------.                 |   | ,-----------------. |     |
  |  | | User process | ...             |   | |   DSP payload   | |     |
  |  | |              `---------------. |   | `-----------------' |     |
  |  | | ,--------------------------. | |   |     ^         |     |     |
  |  | | |  User application code   | | |   |     |         v     |     |
  |  | | `--------------------------' | |   | ,-----------------. |     |
  |  | |             |       ^        | |   | | DSP XRP library | |     |
  |  | |             v       |        | |   | `-----------------' |     |
  |  | | ,--------------------------. | |   |     ^    ^    |     |     |
  |  | | |  Hosted host XRP library | | |   |     |    |    v     |<~.  |
  |  | | `--------------------------' | |   |     | ,-----------. |<~|  |
  |  | `------------ | ----- ^ -------' |   |     | |HW-specific|<~~~|  |
  |  |               |       |          |   |     | |XRP library|<~~~|  |
  |  | ,--------.    |       |          |   |     | `-----------' |  |  |
  |  | | Kernel |    |       |          |   `---- | ------ | -----'  |  |
  |  | |        `--- v ----- | -------. |         v        |         |  |
  |  | | ,--------------------------. | |   ,-----------.  |         |  |
  |  | | |   XRP OS kernel driver   |<----->|   Shared  |  |         |  |
  |  | | `--------------------------' | |   |   memory  |  |         |  |
  |  | |             |       ^        | |   `-----------'  |         |  |
  |  | |             v       |        | |                  v         |  |
  |  | | ,--------------------------. | |            ,-----------.   |  |
  |  | | |  HW-specific XRP  driver |<~~~~~~~~~~~~~~~| Host MMIO |   |  |
  |  | | `--------------------------' | |            `-----------'   |  |
  |  | `---------------- | -----------' |   ,--------------------.   |  |
  |  |                   |              |   |     DSP 0 MMIO     |~~~|  |
  |  |                   `----------------->|     DSP 1 MMIO     |~~~|  |
  |  |                                  |   |         ...        |~~~'  |
  |  `----------------------------------'   `--------------------'      |
  |                                                                     |
  `---------------------------------------------------------------------'
</pre>
\latexonly
\end{minipage}\end{maxsizebox}
\caption{Hosted Host Interacting With the DSP Through the Kernel Driver}
\end{figure}
\endlatexonly

- A hosted host XRP implementation is a library code that runs in a userspace
  processes. It communicates with devices managed by the OS kernel driver
  through the file-based interface exposed by the driver.
- The OS kernel driver consists of the generic XRP implementation and an
  optional hardware-specific XRP driver. The generic XRP driver performs the
  following actions:
  - Loads firmware into the DSP cores, performs initial synchronization, and
    manages the request queue
  - Manages the dedicated physical memory of the Xtensa DSP cores
  - Maps and unmaps the userspace buffers associated with requests making them
    physically contiguous.
  The hardware-specific XRP driver performs the following actions:
  - Manages the Xtensa DSP cores: stalls/unstalls, resets, selects reset vector,
    configures shared memory/used IRQs, clocks, power, and other relevant details
    to get the cores going.
  - Receives IRQs from DSPs and forwards them to the generic XRP driver.
  - Communicates hardware information to the hardware-specific part of the DSP
    XRP library.
- Xtensa DSP side XRP implementation is a library code that runs as a part
  of the firmware on an Xtensa DSP implementing the DSP subset of the XRP API. It
  receives requests, invokes the handler, and sends replies back to the host.

A hosted implementation may run in a system that is separate from the DSP
subsystem. For example, the following configuration is possible: a hosted host XRP
library and a generic XRP kernel driver are running in an emulator that
communicates over shared memory with the DSP subsystem running in an XTSC model.
Hence, it is possible to simulate heterogeneous setups, such as an Aarch64-based
host + Xtensa DSPs.

\latexonly
\begin{figure}[H]
\centering
\begin{maxsizebox}{7cm}{7cm}
\begin{minipage}{\textwidth}
\endlatexonly
<pre>
  ,--------------------------------.        ,-------------------------.
  | Host system simulation process |        | XTSC simulation process |
  |                                `-----.  |                         `------------------.
  | ,-----------.                        |  | ,-------.-------.                          |
  | | Host CPUS |                        |  | | DSP 0 | DSP 1 | ...                      |
  | |           `----------------------. |  | |       `-------------.                    |
  | | ,--------------.                 | |  | | ,-----------------. |                    |
  | | | User process | ...             | |  | | |   DSP payload   | |                    |
  | | |              `---------------. | |  | | `-----------------' |                    |
  | | | ,--------------------------. | | |  | |     ^         |     |                    |
  | | | |  User application code   | | | |  | |     |         v     |                    |
  | | | `--------------------------' | | |  | | ,-----------------. |                    |
  | | |             |       ^        | | |  | | | DSP XRP library | |                    |
  | | |             v       |        | | |  | | `-----------------' |                    |
  | | | ,--------------------------. | | |  | |     ^    ^    |     |                    |
  | | | |  Hosted host XRP library | | | |  | |     |    |    v     |   ,--------------. |
  | | | `--------------------------' | | |  | |     | ,-----------. |   |              | |
  | | `------------ | ----- ^ -------' | |  | |     | |HW-specific| |<~~|  DSP 0 MMIO  | |
  | |               |       |          | |  | |     | |XRP library|<~~~~|  DSP 1 MMIO  | |
  | | ,--------.    |       |          | |  | |     | `-----------' |   |      ...     | |
  | | | Kernel |    |       |          | |  | `---- | --------------'   `--------------' |
  | | |        `--- v ----- | -------. | |  |       |                           ^        |
  | | | ,--------------------------. | | |  |       |                           |        |
  | | | |   XRP OS kernel driver   | | | |  |       |                           |        |
  | | | `--------------------------' | | |  |       |                           |        |
  | | `---------------- ^ -----------' | |  |       |                           |        |
  | `------------------ | -------------' |  |       |                           |        |
  |                     v                |  |       v                           |        |
  | ,-------------------------------------------------------.    ,---------------------. |
  | |                       Shared memory                   |<-->|  Helper LUA script  | |
  | `-------------------------------------------------------'    `---------------------' |
  |                                      |  |                                            |
  `--------------------------------------'  `--------------------------------------------'
</pre>
\latexonly
\end{minipage}\end{maxsizebox}
\caption{Hosted Host System in an Emulator Process Interacting With Standalone
DSP in a Separate XTSC Process}
\end{figure}
\endlatexonly


\section implementations_standalone Standalone Implementation
\idxentry{Implementations!Standalone}

A standalone implementation can run on a Linux-based system that communicates
with Xtensa DSP code running in a simulator on the same Linux-based system.
It consists of the following two parts: the standalone host implementation of the
XRP interface, and the DSP implementation of the XRP interface.
- The standalone host XRP implementation is a library code that runs in a process
  that directly communicates through the shared memory with the Xtensa DSP
  side XRP code.
- The DSP implementation of the XRP interface is the same for both hosted and
  standalone host. The only difference is in the way the DSP firmware gets the
  shared memory address. In hosted mode the kernel driver loads the firmware
  to each DSP. The kernel driver modifies the value of the global symbol
  `xrp_dsp_comm_base` in the DSP firmware image to point to the origin of the
  shared memory for that DSP. In standalone mode that symbol points to another
  symbol, `xrp_dsp_comm_base_magic`, that must be defined (via
  `-Wl,--defsym,xrp_dsp_comm_base_magic=...`, through the linker script, or by
  other means) and point to the origin of the shared memory for that DSP.

\latexonly
\begin{figure}[H]
\centering
\begin{maxsizebox}{7cm}{7cm}
\begin{minipage}{\textwidth}
\endlatexonly
<pre>
  ,--------------.                      ,-------------------------.
  | User process |                      | XTSC simulation process |
  |              `-------------------.  |                         `--------------------.
  |                                  |  |  ,-------.-------.                           |
  |                                  |  |  | DSP 0 | DSP 1 | ...                       |
  |                                  |  |  |       `-------------.                     |
  |  ,-----------------------------. |  |  | ,-----------------. |                     |
  |  |    User application code    | |  |  | |   DSP payload   | |                     |
  |  `-----------------------------' |  |  | `-----------------' |                     |
  |              |       ^           |  |  |     ^         |     |                     |
  |              v       |           |  |  |     |         v     |                     |
  |  ,-----------------------------. |  |  | ,-----------------. |                     |
  |  | Standalone host XRP library | |  |  | | DSP XRP library | |                     |
  |  `-----------------------------' |  |  | `-----------------' |                     |
  |                  ^               |  |  |     ^    ^    |     |                     |
  |                  |               |  |  |     |    |    v     |   ,--------------.  |
  |                  |               |  |  |     | ,-----------. |   |              |  |
  |                  |               |  |  |     | |HW-specific| |<~~|  DSP 0 MMIO  |  |
  |                  |               |  |  |     | |XRP library|<~~~~|  DSP 1 MMIO  |  |
  |                  |               |  |  |     | `-----------' |   |      ...     |  |
  |                  |               |  |  `---- | --------------'   `--------------'  |
  |                  |               |  |        |                           ^         |
  |                  v               |  |        v                           |         |
  |  ,---------------------------------------------------.    ,---------------------.  |
  |  |                    Shared memory                  |<-->|  Helper LUA script  |  |
  |  `---------------------------------------------------'    `---------------------'  |
  |                                  |  |                                              |
  `----------------------------------'  `----------------------------------------------'
</pre>
\latexonly
\end{minipage}\end{maxsizebox}
\caption{Standalone Host Application Process Interacting With Standalone
DSP in a Separate XTSC Process}
\end{figure}
\endlatexonly

The standalone implementation can run natively on a device without an OS or with RTOS
that provides direct access to the hardware, such as memory that is shared with the DSP
and MMIO.

\latexonly
\begin{figure}[H]
\centering
\begin{maxsizebox}{7cm}{7cm}
\begin{minipage}{\textwidth}
\endlatexonly
<pre>
  ,--------.
  | System |
  |        `------------------------------------------------------------.
  |  ,-----------.                          ,-------.-------.           |
  |  | Host CPUS |                          | DSP 0 | DSP 1 | ...       |
  |  |           `----------------------.   |       `-------------.     |
  |  | ,------------------------------. |   | ,-----------------. |     |
  |  | |    User application code     | |   | |   DSP payload   | |     |
  |  | `------------------------------' |   | `-----------------' |     |
  |  |            |       ^             |   |     ^         |     |     |
  |  |            v       |             |   |     |         v     |     |
  |  | ,------------------------------. |   | ,-----------------. |     |
  |  | |  Standalone host XRP library | |   | | DSP XRP library | |     |
  |  | `------------------------------' |   | `-----------------' |     |
  |  |        |       |       ^         |   |     ^    ^    |     |     |
  |  |        |       |       |         |   |     |    |    v     |<~.  |
  |  |        |       |       |         |   |     | ,-----------. |<~|  |
  |  |        |       |       |         |   |     | |HW-specific|<~~~|  |
  |  |        |       |       |         |   |     | |XRP library|<~~~|  |
  |  |        |       |       |         |   |     | `-----------' |  |  |
  |  `------- | ----- | ----- | --------'   `---- | --------------'  |  |
  |           |       v       |                   v                  |  |
  |           |   ,----------------------------------.               |  |
  |           |   |           Shared memory          |               |  |
  |           |   `----------------------------------'               |  |
  |           |                             ,--------------------.   |  |
  |           |                             |     DSP 0 MMIO     |~~~|  |
  |           `---------------------------->|     DSP 1 MMIO     |~~~|  |
  |                                         |         ...        |~~~'  |
  |                                         `--------------------'      |
  `---------------------------------------------------------------------'
</pre>
\latexonly
\end{minipage}\end{maxsizebox}
\caption{Standalone Host Application Process Interacting With the DSP Inside
the Same System}
\end{figure}
\endlatexonly


\section implementations_single Single Image Implementation
\idxentry{Implementations!Single}

A single image implementation can run in a userspace process, natively on a
device, or in simulator with or without an OS.

\latexonly
\begin{figure}[H]
\centering
\begin{maxsizebox}{7cm}{7cm}
\begin{minipage}{\textwidth}
\endlatexonly
<pre>
  ,---------.
  | Process |
  |         `-----------------------------------------------.
  |  ,------------------------------.  ,-----------------.  |
  |  |    User application code     |  |   DSP payload   |  |
  |  `------------------------------'  `-----------------'  |
  |             |       ^                  ^         |      |
  |             v       |                  |         v      |
  |  ,---------------------------------------------------.  |
  |  |               Single image XRP library            |  |
  |  `---------------------------------------------------'  |
  `---------------------------------------------------------'
</pre>
\latexonly
\end{minipage}\end{maxsizebox}
\caption{XRP Application and DSP Payload in Single Image Mode}
\end{figure}
\endlatexonly

\page configuration Configuration
\idxentry{Configuration}

The number and configuration of Xtensa DSPs, details of MMIO registers that
control them, and the location and amount of the shared memory may all change.
The following sections describe how that information is stored.

\section configuration_hosted Hosted Mode
\idxentry{Configuration!Hosted}

  The following parts of the system capture the details of the configuration:

- The kernel device tree. The Linux kernel must have a device tree node for
  each Xtensa DSP managed by the XRP Linux kernel driver. See
  xrp-kernel/cdns,xrp*.txt for the device tree binding information of the
  generic XRP Linux driver.
- The DSP XRP library does not have any hardcoded addresses, but the firmware
  image depends on the LSP used to link it. The LSP does not need to have any
  XRP-specific sections, but it must correctly place the DSP stack and data in
  local memories or in the region of system memory reserved for that DSP.

\section configuration_standalone Standalone Mode
\idxentry{Configuration!Standalone}

  The following parts of the system capture the details of the configuration:

- The device tree. Although there's no Linux kernel and kernel driver involved,
  the configuration is maintained in the same format as in the hosted mode.
  Standalone ELF host running inside the same system or XTSC model of a system
  as Xtensa DSP needs a device node for each managed Xtensa DSP.
  For the standalone host running in a separate process, there must be
  an additional device node for all segments of memory shared with
  Xtensa simulators. See xrp-host/standalone/cdns,sim-shmem.txt for the device
  tree binding information.
- The DSP firmware image built for standalone mode have the base address
  of the communication area in the shared memory built into it in the symbol
  `xrp_dsp_comm_base_magic`. Configuration environment variable `DSP_COMM_BASE` is
  used to set that symbol when building example standalone mode firmware.

\section configuration_single Single Image Mode
\idxentry{Configuration!Single}

In the single image mode the XRP does not depend on the target hardware.
The only configurable parameter is the thread stack size in case XOS threads
are used on Xtensa ELF host. It is captured in the symbol
`xrp_xos_thread_stack_size` and may be adjusted
with `-Wl,--defsym,xrp_xos_thread_stack_size=...` option in `LDFLAGS` at
`configure` or build time.

\page features Features

XRP implementations provide basic functionality and a number of optional
features for the end users.

\section features_operation XRP Operation
\idxentry{Features!Operation}

The DSP payload implements the main function. To start using XRP it must open the
XRP device. After that it may register handlers for one or more namespaces and
start processing incoming XRP messages with the xrp_device_dispatch() function. It
may call xrp_device_poll() to check for incoming messages and
xrp_hw_wait_device_irq() to go into the waiti state when there is no more work to do.

The very first message sequence that the host XRP sends to the DSP is for
synchronization. During the synchronization process, the host communicates whether the host
and DSP use IRQ and IRQ numbers/MMIO register locations. Next, the host and DSP
exchange IRQs in directions where IRQs are used.

Namespace handlers registered by the DSP are the functions with the following
prototype:
<pre>
  enum xrp_status
  xrp_command_handler(void *handler_context,
                      const void *in_data, size_t in_data_size,
                      void *out_data, size_t out_data_size,
                      struct xrp_buffer_group *buffer_group);
</pre>

It is called from the xrp_device_dispatch() function when a command for the
corresponding namespace is received. The function takes command description
from the in_data buffer and associated buffer group from the buffer_group. It
writes command processing results to the out_data buffer and to the relevant
buffers of the buffer group. The function may not retain pointers to any
buffers passed to it for later use and must release all references to buffers
and the buffer group it may have made before returning. The return value shall
reflect whether the command was recognized and processed or not. IOW
XRP_STATUS_SUCCESS should be returned if out_data is filled in, otherwise
XRP_STATUS_FAILURE shall be returned. This return value is then returned from
the xrp_device_dispatch. If it was XRP_STATUS_FAILURE, the host also gets the
XRP_STATUS_FAILURE for the command. The handler_context is a pointer that was
passed to the namespace handler registration function.

The Linux application that uses XRP starts with opening XRP devices with the
xrp_open_device() function. XRP devices may have different capabilities and run
different firmware, there is nothing in the XRP API about it. The Linux application
may need to open XRP device and communicate with it to find its capabilities.
An XRP device is identified by an integer index. After opening the device, the
application must create a command queue with the xrp_create_queue() function.
Once a queue is created, an application can send commands through this queue.
Commands may be sent synchronously with the xrp_run_command_sync function or
asynchronously with the xrp_enqueue_command() function. xrp_run_command_sync() returns
when the command execution is complete. xrp_enqueue_command() returns
immediately, regardless of the completion of the command that it enqueued. It
may return a pointer to the event that becomes signaled when the command is
complete. An application may call the xrp_wait function to wait for the event.
Completion of a command means completion of all preceding commands in the same
command queue.
A command may operate on data buffers, however, it may not reference them by
address as the address spaces of the application and DSP payload may be
different. Instead each contiguous buffer is represented as an xrp_buffer
object, and a group of buffers related to one command is represented as an
xrp_buffer_group object. Individual buffers are referenced by index in the
buffer group.
xrp_buffer object can be created with the xrp_create_buffer() function. It may
be assigned an ordinary userspace memory or the device specific shared memory
may be allocated for it. The difference is that the ordinary userspace memory
may not be the most effective type of memory for communication with the DSP,
because depending on its location and physical contiguity the driver may need
to create a bounce buffer that will be presented to the DSP and copy data
to/from there. Device specific shared memory is guaranteed to be directly
accessible to the DSP firmware code and not require use of intermediate bounce
buffers.
A kernel bounce buffer preserves up to 12 bits of the original buffer's
address alignment, that is the number of contiguous least significant bits of
the bounce buffer address that are equal to zero is not less than that of the
original buffer address or 12, whichever is smaller. If that number is less
than 4 then 4 least significant bits of the original address are preserved.
Here's an example table of possible bounce buffer addresses for various
original buffer addresses:

| Original address | Bounce buffer address | Description                 |
| ---------------- | --------------------- | --------------------------- |
| 0xxxxxxxx1       | 0xxxxxxxx1            | (4 LS bits are preserved)   |
| 0xxxxxxxxc       | 0xxxxxxxxc            | (4 LS bits are preserved)   |
| 0xxxxxxx20       | 0xxxxxxx00            | (at least 5 LS bits are 0)  |
| 0xxxxxx100       | 0xxxxxx900            | (at least 8 LS bits are 0)  |
| 0xxxxxx800       | 0xxxxxx800            | (at least 11 LS bits are 0) |

To access memory of the xrp_buffer object, the buffer or part of it
must be mapped with the xrp_map_buffer() function. A buffer may be mapped for
read only or read/write access. The host specifies allowed access when it adds
the buffer to the buffer group, the DSP will not be able to use the buffer in
a way not enabled by the host. When buffer mapping is no longer needed it may
be unmapped with the xrp_unmap_bufer() function. Each mapping of the buffer must
be unmapped individually. The user is responsible for unmapping buffers before
passing them between the host and the DSP or for making sure that buffer
content is not accessed on one side when it is being processed on the other.

In hosted mode, the XRP Linux kernel driver manages the DSP devices. When the driver
gets loaded or device binding is added through sysfs, the driver's probe
function is called for each matching device node. Depending on the power
management settings of the kernel and of the hardware-specific driver, the
DSP may be initialized once in the driver probe callback and then run
continuously or it may be initialized when the corresponding device is first
opened by the user and shut down after it's been closed by the last user.
See \ref porting_kernel chapter for the description of the DSP life cycle
from the kernel driver point of view. Each configured DSP is represented by a
character device. The Linux userspace XRP library may then open that device and
interact with it by means of ioctl and mmap system calls.

In standalone mode, the XTSC simulator loads firmware images for all simulated
DSP cores. Each firmware image has its communication area address preconfigured
(see \ref implementations_standalone chapter). The shared physical memory simulated by the
XTSC is implemented as shared memory on the host platform. In the Linux case, it
is backed by files in /dev/shm. Linux standalone mode XRP host library uses
device tree blob linked with it to find names of the shared memory files and
addresses of the DSP communication areas. It synchronizes with used DSP nodes
configured in the device tree, the synchronization protocol is the same as in
hosted mode. It is possible to use IRQ for communication from host to the DSP.
A LUA script running in the XTSC polls hardcoded shared memory locations
designated as software IRQ registers and initiates internal write to the real
MMIO IRQ register when such location is written to.
It is not possible to use IRQ for communication from the DSP to the host.

\section features_multiqueue Multiqueue feature
\idxentry{Features!Multiqueue}

An XRP device may provide an option to configure more than one hardware queue
with associated priority. Processing of a request on a queue with higher
priority preempts processing of requests on all lower priority queues.

XRP API provides a function that creates software queue with specific priority:
xrp_create_nsp_queue(). Software queue priorities range from 0 to N - 1, where
N is a number of hardware queues. Hardware queue priorities don't have
predefined range, but higher number must mean higher priority. Mapping between
software queue priority and hardware queue priority is done as follows:
configured hardware queues are sorted in non-descending priority order.
Software priorities are assigned sequentially to the sorted array of hardware
queues. For example, if the following hardware queue priorities are configured
for a device: <7 5 8>, then there are 3 software priorities: 0 goes to the
queue 1 (hardware priority 5), 1 goes to the queue 0 (hardware priority 7), 2
goes to the queue 2 (hardware priority 8). If a software priority higher than
the number of configured hardware queues is requested, it is mapped to the
highest priority hardware queue.

Number and priorities of the hardware queues are specified in `queue-priority`
property of the XRP device node in the device tree. Generic XRP kernel driver
passes this information to the firmware in synchronization step. When firmware
does not recognize the request or cannot support requested priorities XRP
falls back to single hardware queue.

Firmware developer controls how prioritization is done by implementing the
function xrp_user_create_queues() that is called at synchronization time and
must organize processing for requested queue priorities, or report that it
cannot be done. Repeated calls to xrp_user_create_queues() must adjust the
list of active hardware queues and their priorities.
The function xrp_open_device() can be called with device indices corresponding
to the hardware queue indices to open XRP devices for additional hardware
queues. Device polling and message dispatching is done by the usual
xrp_device_poll() and xrp_device_dispatch() functions.

An example implementation of this feature provided in simple-xos port uses XOS
threads and thread priorities to organize request processing. Handler for the
first hardware queue is explicitly created by the example's main() function.
The initial priority of the initial hardware queue thread is chosen by the
main() function. It must be chosen properly with respect to other threads
spawned by the main() function because the initial hardware queue thread will
serve the queue in polling mode until the synchronization with the host is
complete, calling xos_thread_yield() between the polls. After the
synchronization all hardware queue thread priorities will be adjusted as
requested by the host.
Size of the stack allocated for additional threads can be controlled through
the symbol `xrp_user_queue_stack_size` that may be defined with the linker
option `-Wl,--defsym,xrp_user_queue_stack_size=...`
Simple-xos port also requires use of the device in IRQ mode, polling mode
is not supported.

\page porting Porting XRP to a New Hardware Platform
\idxentry{Porting}

XRP may be used on a wide variety of system configurations. While its core logic
does not depend on the hardware details, certain tasks like DSP initialization
or IRQ delivery may need to be very hardware-specific. For this reason, the DSP and
kernel code is organized in a way that supports extension: generic code provides
entry points and uses fixed interface to call hardware-specific operations.

\section porting_dsp Porting XRP DSP Code
\idxentry{Porting!DSP}

The following tasks that XRP firmware performs during the device lifecycle
need detailed knowledge about the hardware:

- Initialization of the hardware-specific code.
- DSP operation parameters initialization: need to be synchronized with the
  hardware-specific XRP kernel driver on the host side.
- Sending IRQ to the host: need to know the location and layout of the
  register that controls IRQ signal.
- Receiving IRQ from the host: need to know interrupt number, IRQ mode, layout
  and location of a register to clear IRQ on the DSP side.
- Going to the low-power state when there's nothing to do: need to be aware of
  other IRQs used on the DSP side.
- Signaling panic to the host.

The XRP DSP library implements generic XRP functionality and expects that the
above functions are implemented externally.

Typical DSP life cycle looks like this on the DSP side:

<pre>
  main()
  {
    xrp_hw_init()
    xrp_open_device()
    for (all static namespaces) {
      xrp_device_register_namespace()
    }
    do {
      if (xrp_device_poll() detects a message from host) {
        xrp_device_dispatch()
          (synchronization)
            xrp_hw_set_sync_data()
            xrp_hw_wait_device_irq()
            xrp_hw_send_host_irq()
          (regular command)
            xrp_hw_send_host_irq()
      } else if (there's no other work to do) {
        xrp_hw_wait_device_irq()
      }
    } while (DSP is active)
  }
</pre>

The main function, namespace handlers registration and message processing loop
are all parts of the DSP payload external to the XRP library. The interface
between them is defined in xrp_dsp_hw.h

Porting XRP DSP to new hardware is done by providing the following
hardware-specific functions for that hardware:

\latexonly
\begin{table}[h]
\caption{DSP Hardware-Specific Functions}
\end{table}
\endlatexonly

| Function                 |
| ------------------------ |
| xrp_hw_init()            |
| xrp_hw_set_sync_data()   |
| xrp_hw_wait_device_irq() |
| xrp_hw_send_host_irq()   |
| xrp_hw_panic()           |

xrp_hw_init() must be called before any other xrp_hw_* function may be called.

xrp_hw_set_sync_data() is called from the message dispatcher when a
synchronization message is received. It gets a pointer to the configuration
information provided by the host side hardware-specific XRP driver, it must
parse it and do required initialization. Synchronization may happen multiple
times during single DSP life cycle.

xrp_hw_wait_device_irq() is called from the message dispatcher when a
synchronization message is received. It waits for the IRQ from the host. It
must do it atomically, i.e. even if IRQ was raised before the call to this
function, the function must detect it and return. Normally the IRQ line
assigned for that purpose will be masked and the function would need to
globally disable interrupts, unmask that IRQ line, invoke waiti instruction
with appropriate level, get to the IRQ handler, clear the IRQ condition in
case it's level-triggered, mask that IRQ line again and restore the original
global IRQ mask state.

xrp_hw_send_host_irq() is called from the message dispatcher to indicate message
handling completion to the host.

xrp_hw_panic() may be called by the user code when it detects a fatal condition
from which it cannot recover: an unhandled exception, failed assertion or a
call to the abort() function. xrp_hw_panic() may notify the host of this
condition.

There's an example hardware-specific DSP XRP library xrp_hw_simple that works
together with the host side xrp_hw_simple kernel driver and may be used as a
template.

\section porting_dsp_cache Caching Shared Memory on the DSP

Initially XRP was developed for use with Vision Xtensa cores that do not have
data cache. Cores that have a data cache are supposed to set up a shared memory
region as uncached and use IDMA to transfer data between the shared memory
buffers and local memory. When it is desirable to use data cache with
shared memory on the DSP side, xrp_device_enable_cache() may be used to turn
on cache management in the DSP XRP code.

\section porting_standalone_host_cache Caching Shared Memory on the Standalone Host

Standalone host running in a separate process as a Linux user application does
not need to care about cache coherency issues, because shared memory in the Linux
userspace is always coherent. Standalone ELF host running in the same XTSC
subsystem or on the same hardware as the Xtensa DSP must manage shared memory
cache properly. Current XRP release only supports hardware-coherent host and
DSP shared memory. In the absence of cache coherency support ELF host must
make sure that shared memory is not cached. It may be done statically by
providing `_memmap_cacheattr_reset` symbol at the host ELF image linking
time, or dynamically by manipulating MMU/MPU entries at runtime.

\latexonly \newpage \endlatexonly
\section porting_kernel Porting the XRP Kernel Driver
\idxentry{Porting!Kernel}

The following tasks that the XRP driver performs during the device lifecycle
need detailed knowledge about the hardware:

- Starting and stopping the DSP: need to control power and clock of the DSP,
  need to know location and layout of the registers that control reset vector
  selection, reset and runstall signals.
- Loading firmware: depending on the way DSP memory is connected to the host
  it may vary greatly.
- Sending IRQ to the DSP: need to know the location and layout of the register
  that controls IRQ signal. Information about IRQ number, IRQ mode, layout and
  location or the register to clear IRQ on the DSP side must be made available
  to the DSP.
- Receiving IRQ from the DSP: need to know interrupt number, IRQ mode, layout
  and location of a register to clear IRQ on the host side.
- Invalidating/flushing cache for DSP memory: may need to be performed in
  architecture-specific device-specific manner.
- Copying data/code to hardware-specific memory or setting it to a specific
  value. This may require specific alignment/access width for written data.
- Detecting that the DSP firmware has crashed and dumping crash log
  information.

The XRP driver is divided into two parts: generic and hardware-specific and
the actions listed above must be implemented in the hardware-specific part.
The interface between parts is defined in the header xrp_hw.h

The generic XRP driver defines three formats of configuration information:
cdns,xrp, cdns,xrp,v1 and cdns,xrp,cma. The difference is in the way the
shared memory region is specified and in the contents of the device registers
(regs device tree property, information returned by the platform_get_resource
function), see cdns,xrp.txt, cdns,xrp,v1.txt and cdns,xrp,cma.txt for
details. The hardware-specific XRP driver should extend one of these
formats and define its own format based on it. At the device probe time the
hardware-specific XRP driver must call xrp_init(), xrp_init_v1() or xrp_init_cma()
(corresponding to the chosen configuration information format) and pass it a
pointer to the platform device being probed, to the xvp structure, to the
xrp_hw_ops structure and an opaque hw_arg pointer. xrp_init() function will
use platform device to get device registers information to initialize xvp
structure. Platform device drvdata will be used by the generic XRP driver,
do not change it in the hardware-specific XRP driver. When CONFIG_OF is
enabled, xrp_init() will use device tree node associated with the platform device
to set up physical address map and get firmware image name. Initialization
functions return a pointer to struct xvp on success or a negative error code
otherwise. At the device removal time hardware-specific XRP driver must call
xrp_deinit() with the pointer to the platform device being removed.

DSP life cycle looks like this on the host side:

<pre>
  xrp_hw_ops::enable
  while (DSP is active) {
    xrp_hw_ops::halt
    xrp_hw_ops::reset
    if (a firmware name is configured for the DSP) {
      (load firmware to DSP)
    }
    xrp_hw_ops::release
    xrp_hw_ops::get_hw_sync_data
    (synchronization)
    do {
      (exchange messages with DSP)
    } while (DSP is active && the last command didn't time out)
  }
  xrp_hw_ops::halt
  xrp_hw_ops::disable
</pre>

DSP is enabled in the xrp_runtime_resume() function and is disabled in the
xrp_runtime_suspend() function. Hardware-specific XRP driver should register
these functions as its platform_driver::driver.pm callbacks. Depending on
whether CONFIG_PM is enabled in the kernel or not these functions will be
called by the runtime PM kernel code (and it may happen multiple times during
the device lifetime) or by the xrp_init() / xrp_deinit() functions.

All of the xrp_hw_ops callback functions may be blocking. When the firmware
cannot be loaded by the generic XRP driver, the hardware-specific XRP can load
it in the xrp_hw_ops::reset callback.

The data returned from the xrp_hw_ops::get_hw_sync_data must be allocated with
one of the kmalloc functions family and have format that the DSP side
hardware-specific part of XRP understands. It will be communicated to the DSP
and passed to the xrp_hw_set_sync_data DSP-side hardware-specific XRP
callback. After that the DSP side of XRP must be capable of exchanging IRQs
with the host in directions chosen in configuration.

The hardware-specific XRP driver must pass the XRP_INIT_USE_HOST_IRQ flag in the
init_flags parameter of the xrp_init() to use IRQ for the DSP-to-host
notification. The hardware-specific XRP driver must install the IRQ handler and
call the xrp_irq_handler() function from it. The xrp_hw_ops::send_irq callback is
used to send IRQ to the DSP.

xrp_hw_ops::cacheable determines if dma_sync_for_device and dma_sync_for_cpu
are able to deal with a range of pages. It is called to determine whether the
memory allocated from the XRP should be mapped cached or uncached to the
userspace.
It is also called for the ordinary userspace memory as well as for the 3rd
party device memory userspace mappings to determine if the mapping may be
shared with DSP directly or a bounce buffer is needed.

xrp_hw_ops::dma_sync_for_device is used to clean (write back), flush (write
back and invalidate) or invalidate an area of user memory shared with the DSP
to transition ownership of that memory to the DSP. xrp_hw_ops::dma_sync_for_cpu
is used to transition ownership of the memory back to host CPU.
Standard Linux cache management functions (from the DMA API) may be used only
when the DSP shared memory is allocated from the system memory, covered by
struct page's and there's no cache aliasing. If that's not the case, then the
hardware-specific XRP driver may use architecture-specific methods of cache
management or forbid direct use of cached memory entirely.

Cache-related functions are optional, if one of them is not provided then the
default implementation is used: memory allocated from the driver is mapped into
the userspace as cached only when it's a system memory and cached system memory
is shared directly with the DSP.

xrp_hw_ops::memcpy_tohw and xrp_hw_ops::memset_io are optional functions used
for copying data/code to the hardware-specific memory. memcpy_tohw and
memset_io with addresses/sizes aligned to 4 are used when these functions are
not specialized.

xrp_hw_ops::panic_check is an optional function that is called in wait loops
associated with synchronization/command completion. If the hardware-specific part
has a way to detect a DSP firmware crash, it may implement this function and
return true to indicate that firmware has crashed. This helps to start the
recovery procedure immediately instead of waiting for the response timeout.
The DSP may provide additional information to aid crash debugging, where the function
may extract and print that information.

Porting the XRP kernel driver to new hardware is accomplished by developing a
hardware-specific driver for that hardware with the functionality described
above. It must be accompanied by the matching hardware-specific library for
the DSP side. See \ref porting_dsp section for details.

An example hardware-specific XRP driver, xrp_hw_simple, is provided that may be used
as a template.

\page building Configuring and Building XRP
\idxentry{Building}

XRP sources are installed along with the Xtensa Tools. The sources can be found
under

<tt><em>\<xtensa_tools_root\></em>/xtensa-elf/src/xrp</tt>

where <tt><em>\<xtensa_tools_root\></em></tt> is the directory the Xtensa
Tools have been installed. The sources are self-contained and can be copied
elsewhere by copying the directory tree under the xrp directory.

The XRP header files are also present in

<tt><em>\<xtensa_tools_root\></em>/xtensa-elf/include</tt>

This is where the compiler will find them if you use the standard include mechanism:

<tt>#include <xrp_api.h></tt>

XRP DSP library code, ELF host library fox Xtensa and ELF single image library for
Xtensa are also provided in binary form ready for linking. Linux hosted host
library, Linux standalone host library, Linux single image library and kernel driver
must be built for a specific system where they will be used.

\section building_libraries Building XRP Libraries
\idxentry{Building!Libraries}

Userspace and firmware code is built using standard autoconf configure + make
sequence. Generated makefile supports all standard targets, e.g. 'make install'
would install generated library and header file into selected directory
structure.

Normally one build directory is configured per host architecture, so, e.g. to
build libraries for a hosted (arm64 + xtensa DSP) system two build directories
are needed: one for the host code (arm64) and one for the DSP code (xtensa).

The following additional switches of the `configure` script control what
parts of the XRP are built and how:

\latexonly
\begin{table}[h]
\caption{Additional configure Script Switches}
\end{table}
\endlatexonly

| Switch                    | Description                             | Default  |
| ------------------------- | --------------------------------------- | -------- |
| --enable-threads          | Enable thread support.                  | `detect` |
| --enable-host             | Build host XRP components.              | `yes`    |
| --enable-dsp              | Build DSP XRP components.               | `detect` |
| --enable-standalone       | Build standalone library/example.       | `yes`    |
| --enable-hosted           | Build hosted library/example.           | `detect` |
| --enable-single           | Build single library/example.           | `yes`    |
| --enable-example          | Build example application.              | `no`     |
| --enable-external         | Build example using external libraries. | `no`     |
| --enable-port[=ARG]       | Enable port ARG.                        | `simple` |
| --enable-all-simple-ports | Build all simple* ports.                | `no`     |
| --with-libfdt             | Prefix of libfdt headers/library.       |          |

- Switch `--enable-threads` (detect by default) enables or disables use of
  thread library for asynchronous processing. Without thread support
  asynchronous operations, like xrp_enqueue_command() will act synchronously.
  `detect` enables thread support when POSIX or XOS threads are available
  for the host system.

- Switches `--enable-host` (on by default) and `--enable-dsp` (on when host
  triplet specifies xtensa host) enable building of host and DSP libraries and
  examples respectively.

- Switches `--enable-hosted` (on when host triplet specifies Linux host),
  `--enable-standalone` (on by default) and `--enable-single` (on by default)
  enable building of hosted variant of library/example, standalone variant or
  single image variant respectively.

- Switch `--enable-example` enables building of the example host application
  and example DSP firmware, when `--enable-host` and `--enable-dsp` are
  enabled respectively.

- Switch `--enable-external` makes example use system headers and libraries
  instead of building them from the bundled source. It may be used to build
  example with XRP headers and libraries supplied with the Xtensa tools.

- Switch `--enable-port` seclects hardware port for building. Hardware port
  is a hardware-specific DSP library, hardware-specific kernel driver and DSP
  side build flags. In this release there are three ports bundled with the XRP
  code called `simple`, `simple-xos` and `hikey960`.

  - `simple` is for the simple XTSC models with MMIO regions for each DSP
    with mandatory reset and runstall registers and optional IRQ register.
  - `simple-xos` is a variant of `simple` port that internally uses XOS and
    supports the multiqueue feature. It has the same hardware requirements
    as the `simple` port.
  - `hikey960` is for the HiFi3 DSP in the HiKey960 platform.

- Switch `--enable-all-simple-ports` selects `simple` and `simple-xos` ports
  in addition to any port enabled with `--enable-port` switch when building
  DSP libraries. This is used for building XRP as a part of Xtensa tools.

- Switch `--with-libfdt` may be used to specify a path to the libfdt headers
  and archive when it is installed in a non-standard location.

Xtensa code needs Cadence toolchain for Xtensa as it uses the Xtensa Processor
Hardware Abstraction Layer, XTOS and XOS.
Provide the following environment variable to the `configure` or to `make`:
  - CC: name of the compiler together with the xtensa core specification.
  Without any other options this will produce all host and DSP XRP libraries
  for xtensa:

<pre>
  $ ./configure --host=xtensa-elf CC=xt-clang
  $ make
</pre>

| File                                  | Description               |
| ------------------------------------- | ------------------------- |
| xrp-host/libxrp-host-standalone.a     | Standalone host library   |
| xrp-host/libxrp-host-single.a         | Single image host library |
| xrp-common/libxrp-common.a            | Common XRP code library   |
| xrp-dsp/simple/libxrp-dsp-hw-simple.a | Simple hardware DSP port  |
| xrp-dsp/libxrp-dsp.a                  | DSP library               |

- host side code needs a toolchain for the host. Without additional
  switches the following will produce Linux XRP libraries for hosted,
  standalone and single-image modes:

<pre>
  $ ./configure
  $ make
</pre>

| File                                  | Description               |
| ------------------------------------- | ------------------------- |
| xrp-host/libxrp-host-standalone.a     | Standalone host library   |
| xrp-host/libxrp-host-hosted.a         | Hosted host library       |
| xrp-host/libxrp-host-single.a         | Single image host library |
| xrp-common/libxrp-common.a            | Common XRP code library   |

\section building_examples Building XRP Examples
\idxentry{Building!Examples}

Example applications may be built in addition to the XRP libraries. The switch
`--enable-standalone` controls building of the standalone libraries and
examples. The switch `--enable-hosted` controls building of the hosted
libraries and examples. The Device Tree Compiler (`dtc`) is required to build
standalone host example code. `dtc` is usually provided as a part of the
`device-tree-compiler` package on GNU/Linux operating systems. In order to use
custom `dtc` binary, the environment variable `DTC` with a path to that `dtc`
binary may be used with `configure` or `make` command.

- adding switch `--enable-example` to the hosted DSP build configuration will
  produce example firmware for hosted mode. Provide the following environment
  variable to the `configure` or `make`:
  - `DSP_LSP`: path to the LSP to be used.
  - `DSP_CACHEATTR`: value for the `_memmap_cacheattr_reset` symbol.

<pre>
  $ ./configure --host=xtensa-elf --disable-host --disable-standalone \
    --enable-example \
    DSP_LSP=vp6-mp/package/cores/DSP_0/xtensa-elf/lib/sim-stacklocal \
    CC='xt-clang --xtensa-core=visionp6_ao'
  $ make
</pre>

  The result is xrp-example/xrp-dsp-hosted. In order to be loaded as a firmware
  it needs to be put to the Linux file system under /lib/modules/firmware and
  its name need to be specified in the "firmware" parameter inside the xrp
  device node in the device tree.

- adding switch `--enable-example` to the standalone DSP build configuration
  will produce example firmware for standalone mode. Provide the following
  environment variable to the `configure` or `make`:
  - `DSP_LSP`: path to the LSP to be used.
  - `DSP_CACHEATTR`: value for the `_memmap_cacheattr_reset` symbol.
  - `DSP_COMM_BASE`: base address of the DSP communication area.

<pre>
  $ ./configure --host=xtensa-elf --disable-host --disable-hosted \
    --enable-standalone --enable-example \
    DSP_LSP=vp6-mp/package/cores/DSP_0/xtensa-elf/lib/sim-stacklocal \
    DSP_COMM_BASE=0x10000000 \
    CC='xt-clang --xtensa-core=visionp6_ao'
  $ make
</pre>

  The result is xrp-example/xrp-dsp-standalone. To be loaded as
  firmware, a path to it must be passed to the XTSC.

- adding switch `--enable-example` to the Linux host build configuration will
  produce example Linux host applications for hosted, standalone and
  single-image modes:

<pre>
  $ ./configure --enable-example
  $ make
</pre>

| File                            | Description                         |
| ------------------------------- | ----------------------------------- |
| xrp-example/xrp-host-hosted     | Hosted host example application     |
| xrp-example/xrp-host-single     | Single image example                |
| xrp-example/xrp-host-standalone | Standalone host example application |

- the following will produce bare-metal examples for standalone and
  single-image modes. Provide the following environment variable to the
  `configure` or `make`:
  - `HOST_LSP`: path to the LSP to be used.
  - `HOST_CACHEATTR`: value for the `_memmap_cacheattr_reset` symbol.

<pre>
  $ ./configure --host=xtensa-elf CC=xt-clang --enable-example
  $ make
</pre>

| File                            | Description                         |
| ------------------------------- | ----------------------------------- |
| xrp-example/xrp-host-single     | Single image example                |
| xrp-example/xrp-host-standalone | Standalone host example application |

\section building_kernel Building the Kernel Driver
\idxentry{Building!Kernel}

The kernel driver is built using a typical kernel module build sequence. At
least the following environment variables/make parameters must be provided by
the user:
- `ARCH`: target Linux architecture
- `KSRC`: points to the configured kernel tree
- `CROSS_COMPILE`: path and prefix name of the cross compiler

xrp-kernel directory is independent from the rest of the XRP build system,
it is not configured by the `configure` script. The Makefile here invokes
the Linux kernel build system. xrp-kernel/Makefile supports targets "modules",
"clean" and all other standard kernel targets. xrp-kernel/Kconfig is not used
when building kernel modules out-of-tree. The whole xrp-kernel directory may
be integrated into the drivers subtree of the Linux kernel, in which case
Makefile of the parent directory shall reference xrp-kernel/Makefile, and
Kconfig of the parent directory shall include xrp-kernel/Kconfig.
Example building modules out-of-tree for the Aarch64 Linux:

<pre>
  $ ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- \
    KSRC=`pwd`/../kernel/build-arm64-3.19 make -C xrp-kernel modules
</pre>

The result is kernel object xrp-kernel/xrp.ko loadable into the kernel it was
built against. To build both xrp.ko and xrp_hw_simple.ko pass
CONFIG_XRP_HW_SIMPLE=m to the make:

<pre>
  $ ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- \
    KSRC=`pwd`/../kernel/build-arm64-3.19 \
    make -C xrp-kernel CONFIG_XRP_HW_SIMPLE=m modules
</pre>

The following XRP kernel module features have additional requirements for the
kernel configuration:
- CMA binding needs CONFIG_CMA and CONFIG_DMA_CMA enabled.

*/
